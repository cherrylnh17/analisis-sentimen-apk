{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **Proses Instalasi**\n"
      ],
      "metadata": {
        "id": "aAAXqPps-lTg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install numpy\n",
        "!pip install pandas\n",
        "!pip install gensim tensorflow\n",
        "!pip install scikit-learn nltk imblearn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "abyyY3Ex-L_E",
        "outputId": "a8ed043e-8d7c-47f5-cf2b-543424a3759e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.12/dist-packages (4.4.0)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.12/dist-packages (2.20.0)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from gensim) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.16.3)\n",
            "Requirement already satisfied: smart_open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.4.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.9.23)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google_pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt_einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.0)\n",
            "Requirement already satisfied: protobuf>=5.28.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.32.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.2.0)\n",
            "Requirement already satisfied: typing_extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.0.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.76.0)\n",
            "Requirement already satisfied: tensorboard~=2.20.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.20.0)\n",
            "Requirement already satisfied: keras>=3.10.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.15.1)\n",
            "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.10.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.10.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.10.0->tensorflow) (0.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.10.5)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.20.0->tensorflow) (3.9)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.20.0->tensorflow) (11.3.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.20.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.20.0->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.10.0->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.10.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow) (0.1.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
            "Requirement already satisfied: imblearn in /usr/local/lib/python3.12/dist-packages (0.0)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.3.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.12/dist-packages (from imblearn) (0.14.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install emoji\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gFUV1N-U9TGb",
        "outputId": "173fa20a-398c-4495-f49b-2a2dd714137a"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: emoji in /usr/local/lib/python3.12/dist-packages (2.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PySastrawi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g8WXybPCDXg8",
        "outputId": "aa2b67ce-5105-44b1-c745-78513201c23a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: PySastrawi in /usr/local/lib/python3.12/dist-packages (1.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Import Library**\n"
      ],
      "metadata": {
        "id": "4oIYDpDT_EGW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "devHiP_Q9E6L",
        "outputId": "6b7ce3ee-fa7d-4fac-8f74-6668395d4efc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import emoji\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional, Input\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from gensim.models import Word2Vec\n",
        "from Sastrawi.Stemmer import StemmerFactory\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Inisialisasi Stemmer dan Kamus Gen Z**\n"
      ],
      "metadata": {
        "id": "o2oAEUyD_QKf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Inisialisasi stemmer Sastrawi\n",
        "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
        "factory = StemmerFactory()\n",
        "stemmer = factory.create_stemmer()\n",
        "\n",
        "# Load kamus gen z\n",
        "slang_df = pd.read_csv('kamus-gen-z.csv')\n",
        "slang_dict = dict(zip(slang_df['slang'], slang_df['formal']))"
      ],
      "metadata": {
        "id": "_sUI1hbwC7KI"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Membaca Dataset Ulasan APK**"
      ],
      "metadata": {
        "id": "fZhlR4YA_aaf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('dataset_apk.csv')\n",
        "print(\"Jumlah data:\", len(df))\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vt98v3Ws9Gzs",
        "outputId": "f6efc8a5-1e5c-4857-da9a-7ca47a213a5d"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Jumlah data: 10000\n",
            "                               reviewId         userName  \\\n",
            "0  130b89b8-2a69-4cc8-ad48-ea73d44f265f  Pengguna Google   \n",
            "1  83672bfd-f4d3-44c9-a13a-09436478e108  Pengguna Google   \n",
            "2  e6f584a1-ba88-4609-8243-d62e7dce5982  Pengguna Google   \n",
            "3  079c5082-b38a-4c82-a78f-5e0ab7496444  Pengguna Google   \n",
            "4  820caf85-f371-445f-80db-6661376e9ce4  Pengguna Google   \n",
            "\n",
            "                                           userImage  \\\n",
            "0  https://play-lh.googleusercontent.com/EGemoI2N...   \n",
            "1  https://play-lh.googleusercontent.com/EGemoI2N...   \n",
            "2  https://play-lh.googleusercontent.com/EGemoI2N...   \n",
            "3  https://play-lh.googleusercontent.com/EGemoI2N...   \n",
            "4  https://play-lh.googleusercontent.com/EGemoI2N...   \n",
            "\n",
            "                                             content  score  thumbsUpCount  \\\n",
            "0                                 bagus buanget cokk      5              0   \n",
            "1  Kalau miliastra wonderland dipisahkan dari gen...      1              0   \n",
            "2  Gamenya bagus sekali, grafik memanjakan sekali...      5              0   \n",
            "3  panjang umur selalu genshin impact dan semoga ...      5              4   \n",
            "4  semenjak update ministra fps jd drop ke 30, pa...      1              0   \n",
            "\n",
            "      reviewCreatedVersion                   at  \\\n",
            "0  6.1.0_38157513_38357358  2025-10-31 08:34:22   \n",
            "1                      NaN  2025-10-31 08:10:14   \n",
            "2  6.1.0_38157513_38357358  2025-10-31 06:20:34   \n",
            "3  6.1.0_38157513_38357358  2025-10-31 05:55:07   \n",
            "4  5.8.0_35245262_35356052  2025-10-31 05:15:55   \n",
            "\n",
            "                                        replyContent            repliedAt  \\\n",
            "0                                                NaN                  NaN   \n",
            "1                                                NaN                  NaN   \n",
            "2  Terima kasih atas dukungan Anda terhadap Gensh...  2021-10-10 13:51:14   \n",
            "3                                                NaN                  NaN   \n",
            "4                                                NaN                  NaN   \n",
            "\n",
            "                appVersion  \n",
            "0  6.1.0_38157513_38357358  \n",
            "1                      NaN  \n",
            "2  6.1.0_38157513_38357358  \n",
            "3  6.1.0_38157513_38357358  \n",
            "4  5.8.0_35245262_35356052  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**## Pelabelan dan Pembersihan Data Ulasan**"
      ],
      "metadata": {
        "id": "fZTv-bY9_hPU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pelabelan sentimen\n",
        "def label_sentiment(score):\n",
        "    if score <= 2: return 'negatif'\n",
        "    elif score == 3: return 'netral'\n",
        "    else: return 'positif'\n",
        "\n",
        "df['sentiment'] = df['score'].apply(label_sentiment)\n",
        "print(\"Distribusi awal:\\n\", df['sentiment'].value_counts().to_string())\n",
        "\n",
        "# Stopwords tambahan dari NLTK\n",
        "stop_words = set(stopwords.words('indonesian')) | {'dan', 'yang', 'di', 'ke', 'nya', 'ini', 'itu'}\n",
        "\n",
        "# Fungsi pembersihan teks\n",
        "def clean_text(text):\n",
        "    text = str(text).lower()\n",
        "    text = emoji.replace_emoji(text, replace='')\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "    text = re.sub(r'\\d+', '', text)\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    words = text.split()\n",
        "    # Mempertahankan kata pendek yg masih relevan\n",
        "    text = ' '.join(slang_dict.get(word, word) for word in words if word not in stop_words or word in ['oke', 'bagus', 'top'])\n",
        "    return stemmer.stem(text)\n",
        "\n",
        "df['cleaned_content'] = df['content'].apply(clean_text)\n",
        "\n",
        "# Oversampling dengan smote setelah TF-IDF\n",
        "tfidf = TfidfVectorizer(max_features=10000, stop_words=list(stop_words), ngram_range=(1, 2))\n",
        "X_tfidf = tfidf.fit_transform(df['cleaned_content']).toarray()\n",
        "y = pd.get_dummies(df['sentiment']).values\n",
        "smote = SMOTE(random_state=42)\n",
        "X_tfidf_smote, y_smote = smote.fit_resample(X_tfidf, np.argmax(y, axis=1))\n",
        "y_smote = pd.get_dummies(y_smote).values\n",
        "df_balanced = pd.DataFrame({'cleaned_content': [' '.join(doc) for doc in tfidf.inverse_transform(X_tfidf_smote)], 'sentiment': np.argmax(y_smote, axis=1)})\n",
        "df_balanced['sentiment'] = df_balanced['sentiment'].map({0: 'negatif', 1: 'netral', 2: 'positif'})\n",
        "print(f\"Jumlah data setelah SMOTE: {len(df_balanced)}\")\n",
        "print(\"Distribusi setelah SMOTE:\\n\", df_balanced['sentiment'].value_counts().to_string())\n",
        "\n",
        "# Fungsi evaluasi data\n",
        "def evaluate_model(y_true, y_pred, set_name=\"\"):\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    print(f\"\\nAkurasi {set_name}: {accuracy * 100:.2f}%\")\n",
        "    print(classification_report(y_true, y_pred, target_names=['negatif', 'netral', 'positif']))\n",
        "    return accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QzsWeAfs9G7B",
        "outputId": "688f32b4-53d7-4084-da8c-40c8f0e52cf0"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distribusi awal:\n",
            " sentiment\n",
            "positif    6345\n",
            "negatif    3028\n",
            "netral      627\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/feature_extraction/text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['baiknya', 'berkali', 'kali', 'kurangnya', 'mata', 'olah', 'sekurang', 'setidak', 'tama', 'tidaknya'] not in stop_words.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Jumlah data setelah SMOTE: 19035\n",
            "Distribusi setelah SMOTE:\n",
            " sentiment\n",
            "positif    6345\n",
            "negatif    6345\n",
            "netral     6345\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Pelatihan Model**"
      ],
      "metadata": {
        "id": "ZEUQ85uo_jhh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Model 1: Neural Network (Dense Layers) dengan Fitur TF-IDF (Data Split 80/20) ---\n",
        "print(\"\\n=== Neural Network (Dense Layers) dengan Fitur TF-IDF (Data Split 80/20) ===\")\n",
        "X_train1, X_test1, y_train1, y_test1 = train_test_split(X_tfidf_smote, y_smote, test_size=0.2, random_state=42)\n",
        "\n",
        "model1 = Sequential([\n",
        "    Input(shape=(10000,)),\n",
        "    Dense(512, activation='relu', kernel_regularizer=l2(0.001)),\n",
        "    Dropout(0.4),\n",
        "    Dense(256, activation='relu', kernel_regularizer=l2(0.001)),\n",
        "    Dropout(0.4),\n",
        "    Dense(3, activation='softmax')\n",
        "])\n",
        "model1.compile(optimizer=Adam(learning_rate=0.0005), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=0.00001)\n",
        "model1.fit(X_train1, y_train1, epochs=30, batch_size=64, validation_split=0.1, callbacks=[early_stopping, lr_scheduler], verbose=1)\n",
        "\n",
        "y_pred_train1 = np.argmax(model1.predict(X_train1), axis=1)\n",
        "y_pred_test1 = np.argmax(model1.predict(X_test1), axis=1)\n",
        "y_train1_cat = np.argmax(y_train1, axis=1)\n",
        "y_test1_cat = np.argmax(y_test1, axis=1)\n",
        "train_acc1 = evaluate_model(y_train1_cat, y_pred_train1, \"Training\")\n",
        "test_acc1 = evaluate_model(y_test1_cat, y_pred_test1, \"Testing\")\n",
        "\n",
        "# --- Model 2: LSTM Neural Network dengan Embedding Word2Vec (Data Split 80/20) ---\n",
        "print(\"\\n=== LSTM Neural Network dengan Embedding Word2Vec (Data Split 80/20) ===\")\n",
        "sentences = [text.split() for text in df_balanced['cleaned_content']]\n",
        "w2v_model = Word2Vec(sentences, vector_size=200, window=5, min_count=1, workers=4, epochs=20)\n",
        "\n",
        "tokenizer = Tokenizer(num_words=10000)\n",
        "tokenizer.fit_on_texts(df_balanced['cleaned_content'])\n",
        "X_seq = tokenizer.texts_to_sequences(df_balanced['cleaned_content'])\n",
        "max_len = 100\n",
        "X_pad = pad_sequences(X_seq, maxlen=max_len)\n",
        "\n",
        "embedding_matrix = np.zeros((10000, 200))\n",
        "for word, i in tokenizer.word_index.items():\n",
        "    if i < 10000 and word in w2v_model.wv:\n",
        "        embedding_matrix[i] = w2v_model.wv[word]\n",
        "\n",
        "X_train2, X_test2, y_train2, y_test2 = train_test_split(X_pad, y_smote, test_size=0.2, random_state=42)\n",
        "\n",
        "model2 = Sequential([\n",
        "    Embedding(10000, 200, weights=[embedding_matrix], input_length=max_len, trainable=True),\n",
        "    Bidirectional(LSTM(256, return_sequences=True, kernel_regularizer=l2(0.005))),\n",
        "    LSTM(128),\n",
        "    Dropout(0.5),\n",
        "    Dense(128, activation='relu', kernel_regularizer=l2(0.005)),\n",
        "    Dropout(0.5),\n",
        "    Dense(3, activation='softmax')\n",
        "])\n",
        "model2.compile(optimizer=Adam(learning_rate=0.0005), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model2.fit(X_train2, y_train2, epochs=30, batch_size=64, validation_split=0.1, callbacks=[early_stopping, lr_scheduler], verbose=1)\n",
        "\n",
        "y_pred_train2 = np.argmax(model2.predict(X_train2), axis=1)\n",
        "y_pred_test2 = np.argmax(model2.predict(X_test2), axis=1)\n",
        "y_train2_cat = np.argmax(y_train2, axis=1)\n",
        "y_test2_cat = np.argmax(y_test2, axis=1)\n",
        "train_acc2 = evaluate_model(y_train2_cat, y_pred_train2, \"Training\")\n",
        "test_acc2 = evaluate_model(y_test2_cat, y_pred_test2, \"Testing\")\n",
        "\n",
        "# --- Model 3: Neural Network (Dense Layers) dengan Fitur TF-IDF (Data Split 70/30) ---\n",
        "print(\"\\n=== Neural Network (Dense Layers) dengan Fitur TF-IDF (Data Split 70/30) ===\")\n",
        "X_train3, X_test3, y_train3, y_test3 = train_test_split(X_tfidf_smote, y_smote, test_size=0.3, random_state=42)\n",
        "\n",
        "model3 = Sequential([\n",
        "    Input(shape=(10000,)),\n",
        "    Dense(512, activation='relu', kernel_regularizer=l2(0.001)),\n",
        "    Dropout(0.4),\n",
        "    Dense(256, activation='relu', kernel_regularizer=l2(0.001)),\n",
        "    Dropout(0.4),\n",
        "    Dense(3, activation='softmax')\n",
        "])\n",
        "model3.compile(optimizer=Adam(learning_rate=0.0005), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model3.fit(X_train3, y_train3, epochs=30, batch_size=64, validation_split=0.1, callbacks=[early_stopping, lr_scheduler], verbose=1)\n",
        "\n",
        "y_pred_train3 = np.argmax(model3.predict(X_train3), axis=1)\n",
        "y_pred_test3 = np.argmax(model3.predict(X_test3), axis=1)\n",
        "y_train3_cat = np.argmax(y_train3, axis=1)\n",
        "y_test3_cat = np.argmax(y_test3, axis=1)\n",
        "train_acc3 = evaluate_model(y_train3_cat, y_pred_train3, \"Training\")\n",
        "test_acc3 = evaluate_model(y_test3_cat, y_pred_test3, \"Testing\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qTTvO7Do9HJG",
        "outputId": "6d237bb0-76a0-4468-a868-aefc784c40ad"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Neural Network (Dense Layers) dengan Fitur TF-IDF (Data Split 80/20) ===\n",
            "Epoch 1/30\n",
            "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 94ms/step - accuracy: 0.5415 - loss: 1.4403 - val_accuracy: 0.7630 - val_loss: 0.8181 - learning_rate: 5.0000e-04\n",
            "Epoch 2/30\n",
            "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 95ms/step - accuracy: 0.8095 - loss: 0.7226 - val_accuracy: 0.8253 - val_loss: 0.7459 - learning_rate: 5.0000e-04\n",
            "Epoch 3/30\n",
            "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 92ms/step - accuracy: 0.8568 - loss: 0.6403 - val_accuracy: 0.8313 - val_loss: 0.7208 - learning_rate: 5.0000e-04\n",
            "Epoch 4/30\n",
            "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 101ms/step - accuracy: 0.8830 - loss: 0.5846 - val_accuracy: 0.8293 - val_loss: 0.7152 - learning_rate: 5.0000e-04\n",
            "Epoch 5/30\n",
            "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 92ms/step - accuracy: 0.8963 - loss: 0.5666 - val_accuracy: 0.8306 - val_loss: 0.7051 - learning_rate: 5.0000e-04\n",
            "Epoch 6/30\n",
            "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 94ms/step - accuracy: 0.9099 - loss: 0.5251 - val_accuracy: 0.8464 - val_loss: 0.6997 - learning_rate: 5.0000e-04\n",
            "Epoch 7/30\n",
            "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 96ms/step - accuracy: 0.9051 - loss: 0.5213 - val_accuracy: 0.8450 - val_loss: 0.6837 - learning_rate: 5.0000e-04\n",
            "Epoch 8/30\n",
            "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 97ms/step - accuracy: 0.9107 - loss: 0.5024 - val_accuracy: 0.8444 - val_loss: 0.6896 - learning_rate: 5.0000e-04\n",
            "Epoch 9/30\n",
            "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 98ms/step - accuracy: 0.9177 - loss: 0.4864 - val_accuracy: 0.8516 - val_loss: 0.6714 - learning_rate: 5.0000e-04\n",
            "Epoch 10/30\n",
            "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 96ms/step - accuracy: 0.9197 - loss: 0.4771 - val_accuracy: 0.8352 - val_loss: 0.6789 - learning_rate: 5.0000e-04\n",
            "Epoch 11/30\n",
            "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 93ms/step - accuracy: 0.9173 - loss: 0.4690 - val_accuracy: 0.8227 - val_loss: 0.6985 - learning_rate: 5.0000e-04\n",
            "Epoch 12/30\n",
            "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 94ms/step - accuracy: 0.9297 - loss: 0.4400 - val_accuracy: 0.8510 - val_loss: 0.6454 - learning_rate: 1.0000e-04\n",
            "Epoch 13/30\n",
            "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 95ms/step - accuracy: 0.9347 - loss: 0.4064 - val_accuracy: 0.8555 - val_loss: 0.6227 - learning_rate: 1.0000e-04\n",
            "Epoch 14/30\n",
            "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 91ms/step - accuracy: 0.9350 - loss: 0.3905 - val_accuracy: 0.8496 - val_loss: 0.6174 - learning_rate: 1.0000e-04\n",
            "Epoch 15/30\n",
            "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 98ms/step - accuracy: 0.9399 - loss: 0.3662 - val_accuracy: 0.8549 - val_loss: 0.6088 - learning_rate: 1.0000e-04\n",
            "Epoch 16/30\n",
            "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 93ms/step - accuracy: 0.9402 - loss: 0.3609 - val_accuracy: 0.8496 - val_loss: 0.5990 - learning_rate: 1.0000e-04\n",
            "Epoch 17/30\n",
            "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 95ms/step - accuracy: 0.9402 - loss: 0.3575 - val_accuracy: 0.8562 - val_loss: 0.5903 - learning_rate: 1.0000e-04\n",
            "Epoch 18/30\n",
            "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 96ms/step - accuracy: 0.9380 - loss: 0.3621 - val_accuracy: 0.8496 - val_loss: 0.5938 - learning_rate: 1.0000e-04\n",
            "Epoch 19/30\n",
            "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 92ms/step - accuracy: 0.9411 - loss: 0.3459 - val_accuracy: 0.8523 - val_loss: 0.5834 - learning_rate: 1.0000e-04\n",
            "Epoch 20/30\n",
            "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 96ms/step - accuracy: 0.9399 - loss: 0.3458 - val_accuracy: 0.8523 - val_loss: 0.5842 - learning_rate: 1.0000e-04\n",
            "Epoch 21/30\n",
            "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 94ms/step - accuracy: 0.9370 - loss: 0.3491 - val_accuracy: 0.8523 - val_loss: 0.5834 - learning_rate: 1.0000e-04\n",
            "Epoch 22/30\n",
            "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 97ms/step - accuracy: 0.9420 - loss: 0.3329 - val_accuracy: 0.8483 - val_loss: 0.5870 - learning_rate: 2.0000e-05\n",
            "Epoch 23/30\n",
            "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 93ms/step - accuracy: 0.9411 - loss: 0.3321 - val_accuracy: 0.8496 - val_loss: 0.5849 - learning_rate: 2.0000e-05\n",
            "Epoch 24/30\n",
            "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 96ms/step - accuracy: 0.9389 - loss: 0.3365 - val_accuracy: 0.8503 - val_loss: 0.5818 - learning_rate: 1.0000e-05\n",
            "Epoch 25/30\n",
            "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 93ms/step - accuracy: 0.9374 - loss: 0.3360 - val_accuracy: 0.8490 - val_loss: 0.5810 - learning_rate: 1.0000e-05\n",
            "Epoch 26/30\n",
            "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 98ms/step - accuracy: 0.9397 - loss: 0.3297 - val_accuracy: 0.8510 - val_loss: 0.5812 - learning_rate: 1.0000e-05\n",
            "Epoch 27/30\n",
            "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 97ms/step - accuracy: 0.9402 - loss: 0.3313 - val_accuracy: 0.8470 - val_loss: 0.5798 - learning_rate: 1.0000e-05\n",
            "Epoch 28/30\n",
            "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 93ms/step - accuracy: 0.9378 - loss: 0.3320 - val_accuracy: 0.8477 - val_loss: 0.5811 - learning_rate: 1.0000e-05\n",
            "Epoch 29/30\n",
            "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 97ms/step - accuracy: 0.9377 - loss: 0.3306 - val_accuracy: 0.8483 - val_loss: 0.5800 - learning_rate: 1.0000e-05\n",
            "Epoch 30/30\n",
            "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 92ms/step - accuracy: 0.9394 - loss: 0.3313 - val_accuracy: 0.8470 - val_loss: 0.5796 - learning_rate: 1.0000e-05\n",
            "\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step\n",
            "\n",
            "Akurasi Training: 93.58%\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     negatif       0.94      0.93      0.93      5075\n",
            "      netral       0.91      0.96      0.93      5094\n",
            "     positif       0.97      0.92      0.94      5059\n",
            "\n",
            "    accuracy                           0.94     15228\n",
            "   macro avg       0.94      0.94      0.94     15228\n",
            "weighted avg       0.94      0.94      0.94     15228\n",
            "\n",
            "\n",
            "Akurasi Testing: 84.48%\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     negatif       0.82      0.85      0.84      1270\n",
            "      netral       0.81      0.96      0.88      1251\n",
            "     positif       0.92      0.73      0.81      1286\n",
            "\n",
            "    accuracy                           0.84      3807\n",
            "   macro avg       0.85      0.85      0.84      3807\n",
            "weighted avg       0.85      0.84      0.84      3807\n",
            "\n",
            "\n",
            "=== LSTM Neural Network dengan Embedding Word2Vec (Data Split 80/20) ===\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m368s\u001b[0m 2s/step - accuracy: 0.5274 - loss: 3.3191 - val_accuracy: 0.6461 - val_loss: 1.3671 - learning_rate: 5.0000e-04\n",
            "Epoch 2/30\n",
            "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m390s\u001b[0m 2s/step - accuracy: 0.6311 - loss: 1.2903 - val_accuracy: 0.6881 - val_loss: 1.0385 - learning_rate: 5.0000e-04\n",
            "Epoch 3/30\n",
            "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m354s\u001b[0m 2s/step - accuracy: 0.6919 - loss: 0.9889 - val_accuracy: 0.7104 - val_loss: 0.8592 - learning_rate: 5.0000e-04\n",
            "Epoch 4/30\n",
            "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m350s\u001b[0m 2s/step - accuracy: 0.7293 - loss: 0.8409 - val_accuracy: 0.7649 - val_loss: 0.7645 - learning_rate: 5.0000e-04\n",
            "Epoch 5/30\n",
            "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m381s\u001b[0m 2s/step - accuracy: 0.7750 - loss: 0.7205 - val_accuracy: 0.7932 - val_loss: 0.6752 - learning_rate: 5.0000e-04\n",
            "Epoch 6/30\n",
            "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m357s\u001b[0m 2s/step - accuracy: 0.8068 - loss: 0.6473 - val_accuracy: 0.7853 - val_loss: 0.6670 - learning_rate: 5.0000e-04\n",
            "Epoch 7/30\n",
            "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m374s\u001b[0m 2s/step - accuracy: 0.8268 - loss: 0.5902 - val_accuracy: 0.8011 - val_loss: 0.6356 - learning_rate: 5.0000e-04\n",
            "Epoch 8/30\n",
            "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m348s\u001b[0m 2s/step - accuracy: 0.8343 - loss: 0.5610 - val_accuracy: 0.8293 - val_loss: 0.5626 - learning_rate: 5.0000e-04\n",
            "Epoch 9/30\n",
            "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m384s\u001b[0m 2s/step - accuracy: 0.8515 - loss: 0.5083 - val_accuracy: 0.8332 - val_loss: 0.5556 - learning_rate: 5.0000e-04\n",
            "Epoch 10/30\n",
            "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m350s\u001b[0m 2s/step - accuracy: 0.8567 - loss: 0.4966 - val_accuracy: 0.8234 - val_loss: 0.5792 - learning_rate: 5.0000e-04\n",
            "Epoch 11/30\n",
            "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m392s\u001b[0m 2s/step - accuracy: 0.8705 - loss: 0.4679 - val_accuracy: 0.8326 - val_loss: 0.5616 - learning_rate: 5.0000e-04\n",
            "Epoch 12/30\n",
            "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m376s\u001b[0m 2s/step - accuracy: 0.8910 - loss: 0.4134 - val_accuracy: 0.8588 - val_loss: 0.5133 - learning_rate: 1.0000e-04\n",
            "Epoch 13/30\n",
            "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m352s\u001b[0m 2s/step - accuracy: 0.9011 - loss: 0.3682 - val_accuracy: 0.8621 - val_loss: 0.5126 - learning_rate: 1.0000e-04\n",
            "Epoch 14/30\n",
            "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m363s\u001b[0m 2s/step - accuracy: 0.9064 - loss: 0.3447 - val_accuracy: 0.8582 - val_loss: 0.5270 - learning_rate: 1.0000e-04\n",
            "Epoch 15/30\n",
            "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m365s\u001b[0m 2s/step - accuracy: 0.9091 - loss: 0.3358 - val_accuracy: 0.8621 - val_loss: 0.5222 - learning_rate: 1.0000e-04\n",
            "Epoch 16/30\n",
            "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m354s\u001b[0m 2s/step - accuracy: 0.9077 - loss: 0.3319 - val_accuracy: 0.8661 - val_loss: 0.5218 - learning_rate: 2.0000e-05\n",
            "Epoch 17/30\n",
            "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m382s\u001b[0m 2s/step - accuracy: 0.9220 - loss: 0.3018 - val_accuracy: 0.8661 - val_loss: 0.5317 - learning_rate: 2.0000e-05\n",
            "Epoch 18/30\n",
            "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m360s\u001b[0m 2s/step - accuracy: 0.9183 - loss: 0.3084 - val_accuracy: 0.8667 - val_loss: 0.5348 - learning_rate: 1.0000e-05\n",
            "\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 291ms/step\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 284ms/step\n",
            "\n",
            "Akurasi Training: 90.50%\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     negatif       0.86      0.91      0.89      5075\n",
            "      netral       0.95      0.94      0.95      5094\n",
            "     positif       0.91      0.86      0.88      5059\n",
            "\n",
            "    accuracy                           0.90     15228\n",
            "   macro avg       0.91      0.90      0.90     15228\n",
            "weighted avg       0.91      0.90      0.91     15228\n",
            "\n",
            "\n",
            "Akurasi Testing: 85.37%\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     negatif       0.81      0.85      0.83      1270\n",
            "      netral       0.89      0.94      0.91      1251\n",
            "     positif       0.86      0.77      0.82      1286\n",
            "\n",
            "    accuracy                           0.85      3807\n",
            "   macro avg       0.85      0.85      0.85      3807\n",
            "weighted avg       0.85      0.85      0.85      3807\n",
            "\n",
            "\n",
            "=== Neural Network (Dense Layers) dengan Fitur TF-IDF (Data Split 70/30) ===\n",
            "Epoch 1/30\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 104ms/step - accuracy: 0.5036 - loss: 1.4850 - val_accuracy: 0.7359 - val_loss: 0.8309 - learning_rate: 5.0000e-04\n",
            "Epoch 2/30\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 98ms/step - accuracy: 0.7848 - loss: 0.7701 - val_accuracy: 0.7914 - val_loss: 0.7549 - learning_rate: 5.0000e-04\n",
            "Epoch 3/30\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 100ms/step - accuracy: 0.8603 - loss: 0.6307 - val_accuracy: 0.8275 - val_loss: 0.7177 - learning_rate: 5.0000e-04\n",
            "Epoch 4/30\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 96ms/step - accuracy: 0.8854 - loss: 0.5833 - val_accuracy: 0.8200 - val_loss: 0.7240 - learning_rate: 5.0000e-04\n",
            "Epoch 5/30\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 96ms/step - accuracy: 0.8944 - loss: 0.5512 - val_accuracy: 0.8462 - val_loss: 0.6953 - learning_rate: 5.0000e-04\n",
            "Epoch 6/30\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 98ms/step - accuracy: 0.9014 - loss: 0.5432 - val_accuracy: 0.8080 - val_loss: 0.7410 - learning_rate: 5.0000e-04\n",
            "Epoch 7/30\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 101ms/step - accuracy: 0.9106 - loss: 0.5075 - val_accuracy: 0.8297 - val_loss: 0.7005 - learning_rate: 5.0000e-04\n",
            "Epoch 8/30\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 101ms/step - accuracy: 0.9218 - loss: 0.4812 - val_accuracy: 0.8365 - val_loss: 0.6789 - learning_rate: 1.0000e-04\n",
            "Epoch 9/30\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 97ms/step - accuracy: 0.9285 - loss: 0.4451 - val_accuracy: 0.8342 - val_loss: 0.6639 - learning_rate: 1.0000e-04\n",
            "Epoch 10/30\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 103ms/step - accuracy: 0.9316 - loss: 0.4243 - val_accuracy: 0.8357 - val_loss: 0.6504 - learning_rate: 1.0000e-04\n",
            "Epoch 11/30\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 95ms/step - accuracy: 0.9298 - loss: 0.4110 - val_accuracy: 0.8350 - val_loss: 0.6454 - learning_rate: 1.0000e-04\n",
            "Epoch 12/30\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 101ms/step - accuracy: 0.9304 - loss: 0.4049 - val_accuracy: 0.8387 - val_loss: 0.6383 - learning_rate: 1.0000e-04\n",
            "Epoch 13/30\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 102ms/step - accuracy: 0.9346 - loss: 0.3916 - val_accuracy: 0.8395 - val_loss: 0.6321 - learning_rate: 1.0000e-04\n",
            "Epoch 14/30\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 101ms/step - accuracy: 0.9353 - loss: 0.3864 - val_accuracy: 0.8372 - val_loss: 0.6247 - learning_rate: 1.0000e-04\n",
            "Epoch 15/30\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 97ms/step - accuracy: 0.9297 - loss: 0.3909 - val_accuracy: 0.8395 - val_loss: 0.6221 - learning_rate: 1.0000e-04\n",
            "Epoch 16/30\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 102ms/step - accuracy: 0.9394 - loss: 0.3761 - val_accuracy: 0.8410 - val_loss: 0.6224 - learning_rate: 1.0000e-04\n",
            "Epoch 17/30\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 97ms/step - accuracy: 0.9359 - loss: 0.3824 - val_accuracy: 0.8432 - val_loss: 0.6167 - learning_rate: 1.0000e-04\n",
            "Epoch 18/30\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 97ms/step - accuracy: 0.9330 - loss: 0.3834 - val_accuracy: 0.8402 - val_loss: 0.6109 - learning_rate: 1.0000e-04\n",
            "Epoch 19/30\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 107ms/step - accuracy: 0.9330 - loss: 0.3726 - val_accuracy: 0.8417 - val_loss: 0.6154 - learning_rate: 1.0000e-04\n",
            "Epoch 20/30\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 101ms/step - accuracy: 0.9321 - loss: 0.3702 - val_accuracy: 0.8410 - val_loss: 0.6113 - learning_rate: 1.0000e-04\n",
            "Epoch 21/30\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 96ms/step - accuracy: 0.9366 - loss: 0.3615 - val_accuracy: 0.8432 - val_loss: 0.6150 - learning_rate: 2.0000e-05\n",
            "Epoch 22/30\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 103ms/step - accuracy: 0.9364 - loss: 0.3570 - val_accuracy: 0.8425 - val_loss: 0.6172 - learning_rate: 2.0000e-05\n",
            "Epoch 23/30\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 97ms/step - accuracy: 0.9378 - loss: 0.3536 - val_accuracy: 0.8425 - val_loss: 0.6126 - learning_rate: 1.0000e-05\n",
            "\u001b[1m417/417\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step\n",
            "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step\n",
            "\n",
            "Akurasi Training: 93.13%\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     negatif       0.93      0.93      0.93      4456\n",
            "      netral       0.90      0.95      0.93      4452\n",
            "     positif       0.96      0.92      0.94      4416\n",
            "\n",
            "    accuracy                           0.93     13324\n",
            "   macro avg       0.93      0.93      0.93     13324\n",
            "weighted avg       0.93      0.93      0.93     13324\n",
            "\n",
            "\n",
            "Akurasi Testing: 83.30%\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     negatif       0.81      0.83      0.82      1889\n",
            "      netral       0.81      0.94      0.87      1893\n",
            "     positif       0.90      0.73      0.81      1929\n",
            "\n",
            "    accuracy                           0.83      5711\n",
            "   macro avg       0.84      0.83      0.83      5711\n",
            "weighted avg       0.84      0.83      0.83      5711\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Prediksi Teks Baru / Belum ada di training**"
      ],
      "metadata": {
        "id": "p1JeIBwD_sHN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fungsi inference\n",
        "def predict_sentiment(text, model, vectorizer, is_word2vec=False, tokenizer=None, max_len=100):\n",
        "    cleaned_text = clean_text(text)\n",
        "    if is_word2vec:\n",
        "        seq = tokenizer.texts_to_sequences([cleaned_text])\n",
        "        padded = pad_sequences(seq, maxlen=max_len)\n",
        "        pred = model.predict(padded)\n",
        "    else:\n",
        "        tfidf_vec = vectorizer.transform([cleaned_text]).toarray()\n",
        "        pred = model.predict(tfidf_vec)\n",
        "    sentiment = np.argmax(pred, axis=1)[0]\n",
        "    return ['negatif', 'netral', 'positif'][sentiment]\n",
        "\n",
        "# contoh hasilnya\n",
        "sample_text = \"Gimana ya, dilihat lihat dari komentarnya sepertinya game ini menarik sekali\"\n",
        "print(\"\\nContoh Inference:\")\n",
        "print(f\"Skema 1 (Dense+TF-IDF): {predict_sentiment(sample_text, model1, tfidf)}\")\n",
        "print(f\"Skema 2 (LSTM+Word2Vec): {predict_sentiment(sample_text, model2, None, True, tokenizer, max_len)}\")\n",
        "print(f\"Skema 3 (Dense+TF-IDF): {predict_sentiment(sample_text, model3, tfidf)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f5eACFUk9HQ3",
        "outputId": "a9306986-b30c-4ebe-9bb6-5c4beb1329e4"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Contoh Inference:\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
            "Skema 1 (Dense+TF-IDF): positif\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step\n",
            "Skema 2 (LSTM+Word2Vec): positif\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
            "Skema 3 (Dense+TF-IDF): positif\n"
          ]
        }
      ]
    }
  ]
}